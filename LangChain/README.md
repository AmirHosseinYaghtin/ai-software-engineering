# LangChain Projects ðŸ“š

This folder contains a collection of practical notebooks built while learning and experimenting with LangChain â€” a flexible framework for creating Large Language Model (LLM) applications.

The projects focus on using Google Gemini models via LangChain, covering core concepts like prompt management, chains, vector stores, tool integration, and retrieval-augmented generation (RAG).

## ðŸ“’ Notebooks

- `1_prompts_gemini`  
  Simple prompt engineering examples using Gemini through LangChain.

- `2-chains_gemini`  
  Demonstrates how to build sequential and custom chains to combine multiple LLM calls.

- `3_vector_stores_gemini`  
  Shows how to create and query vector stores (FAISS, Chroma) for document retrieval with LLMs.

- `4-tools_agents_gemini`  
  Example of creating a simple agent with tools to handle dynamic multi-step tasks.

- `5-RAG-GardeningAgent_gemini`  
  A RAG-based chatbot that answers gardening-related questions using a local document vector store.

- `6-RAG-WikipediaScraper_gemini`  
  A retrieval-augmented chatbot using Wikipedia content scraped and indexed in a vector store.

## ðŸŽ¯ Purpose

To gain hands-on experience with LangChainâ€™s core modules â€” including prompts, chains, agents, tools, retrievers, and vector stores â€” and explore how they can be combined to build practical LLM applications.

## ðŸ“Œ Note

These projects are for learning and demonstration purposes. Code is written with clarity and modularity in mind and can be extended into larger services or APIs later.

